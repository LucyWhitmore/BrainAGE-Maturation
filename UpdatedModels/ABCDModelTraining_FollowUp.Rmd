---
title: "Train BrainAGE with tidymodels"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5)
```


```{r}
library(tidymodels)
library(xgboost)
```

```{r}
#load("/Volumes/devbrainlab/Lucy/BrainAGE/FYP/training_sample_baseline.Rds")
load("~/Documents/FYP/Revisions/model2_features_followup.Rda")

model2_features_followup_noid <- model2_features_followup %>% 
  select(-c(src_subject_id))

#training_subset_test <- training_sample_baseline[1:100,]


# Model prep: split, preprocessing, CV ------------------------------------

# Train / test split ------------------------------------------------------

set.seed(42)
df_split_followup <- initial_split(
  model2_features_followup_noid, 
  prop = 0.80,
  # matching age distributions across train and test set
  strata = "interview_age"
)
df_train_followup <- training(df_split_followup)
df_validation_followup <- testing(df_split_followup)

```


# Pre-processing setup ----------------------------------------------------

```{r}
# define (what we want to do)
preprocess_recipe_followup <- df_train_followup %>%
  # predict scan age by all brain features
  recipe(interview_age ~ .) %>%
  # remove near zero variance predictors
  step_nzv(all_predictors()) %>%
  prep() # where it all gets calculated

preprocess_recipe_followup


# Apply pre-processing ----------------------------------------------------

# juice() will work with training data, `bake()` to apply this to our test data

# apply on train (gives processed value)
df_train_followup_prep <- juice(preprocess_recipe_followup)

# apply on validation
df_validation_followup_prep <- preprocess_recipe %>% bake(df_validation_followup)

```


```{r}
boost_mod_followup <- boost_tree(
  mode = "regression", 
  trees = 150, 
  tree_depth = tune(), min_n = tune(), loss_reduction = tune(),
  # randomness
  sample_size = tune(), mtry = tune(), 
  # step size
  learn_rate = tune()
) %>%
  set_engine("xgboost", 
             objective = "reg:squarederror")

```


```{r}
set.seed(42)

xgboost_grid_followup <- grid_latin_hypercube(
  min_n(), 
  tree_depth(), 
  loss_reduction(),
  sample_size = sample_prop(),
  # has unknown, finalize with data to find max
  finalize(mtry(), df_train_followup_prep),
  learn_rate(),
  size = 500 
)

```

```{r}
xgb_wf_followup <- workflow() %>%
  add_formula(interview_age ~ .) %>%
  add_model(boost_mod_followup)

xgb_wf_followup
```


```{r}
set.seed(42)

train_cv_followup <- df_train_followup_prep %>%
  vfold_cv(
    v = 10, 
    repeats = 10, 
    strata = interview_age
  )
```

```{r}
doParallel::registerDoParallel()

set.seed(42)

xgb_tuned_results_followup <- tune_grid(
  xgb_wf_followup,
  resamples = train_cv_followup,
  grid = xgboost_grid_followup,
  metrics = metric_set(mae, rmse, rsq),
  control = control_grid(verbose = TRUE,
                         save_pred = TRUE)
)

xgb_tuned_results_followup
```

```{r}
xgb_tuned_results_followup %>%
  # want to minimize MAE
  show_best("mae") 

# select parsimonious params within one SE of best model
best_xgb_params_followup <- xgb_tuned_results_followup %>%
  select_by_one_std_err(metric = "mae", maximize = FALSE, tree_depth) 

```

Finalize workflow and fit final model
```{r}
final_xgb_combat_followup <- finalize_workflow(
  xgb_wf_followup,
  best_xgb_params_followup
)

final_xgb_combat_followup

fit_workflow_combat_followup <- fit(final_xgb_combat_followup, df_train_followup_prep)


#xgb_final_mod_test <- boost_mod_test %>%
 # finalize_model(best_xgb_params_test) %>%
 # fit(interview_age ~ .,
#      data = df_train_prep)

```

Variable importance, ignore
```{r}
library(vip)

final_xgb_combat_followup %>%
  fit(data = df_train_followup) %>%
  extract_fit_parsnip() %>%
  vip(geom = "point")

```

```{r}
final_res_followup <- last_fit(final_xgb_combat_followup, df_split_followup)

collect_metrics(final_res_followup)
```

Save models
```{r}
# three different save formats just in case
# 1. Rds
save(fit_workflow_combat_followup, file = "fit_workflow_combat_followup.rds")
# 2. rda
save(fit_workflow_combat_followup, file = "fit_workflow_2_combat_followup.rda")
# 3. raw xbg object, which can then be loaded with xgb.load
abcd_model_obj_combat_followup <- fit_workflow_combat_followup$fit$fit$fit
xgb.save(abcd_model_obj_combat_followup, "abcd_model_obj_combat_followup")
```

Model bundling, ignore for now
```{r}
# Testing out bundling
#mod_bundle <- bundle::bundle(fit_workflow)
#save(mod_bundle, file = "xgb_workflow_bundles.rds")

#save(mod_bundle, file = "xgb_workflow.rds")

# in a new R session:
#mod_bundle <- readRDS("path/to/file.rds")
#mod_new <- unbundle(mod_bundle)

#xgb.save.raw(fit_workflow$fit$fit, raw_format = "deprecated")


#model_obj <- fit_workflow$fit$fit$fit
#xgb.save(model_obj, "model_obj")


#xgb.save.raw(model_obj, "model_obj_raw")
```

Predict
```{r}
load("/Volumes/devbrainlab/Lucy/BrainAGE/FYP/Revisions/model2_analysis_followup.Rds")


brain_age_df_workflow_combat_followup <- fit_workflow_combat_followup %>%
  predict(new_data = model2_analysis_followup) %>%
  mutate(
    # provide the chronological age at time of scan
    truth = model2_analysis_followup$interview_age
  ) %>%
  # compute the brain age gap by subtracting chronological age from prediction
  mutate(gap = .pred - truth)
```

Alternate/Backup Prediction - Use if prior version doesn't work
```{r}
# The following version converts the workflow object to a raw xgb object. Over the course of the project, we've discovered that certain features in the xgboost package haven't always worked with updates within tidymodels. In case of deprecation of certain functions/ (or issues with version compatibility), this code should let you access the actual xgboost object, which can then be used to make model predictions. I don't anticipate this will be needed, but if the code on lines 221-233 doesn't work, this might! 

abcd_model_obj_combat_followup <- fit_workflow_combat_followup$fit$fit$fit

# combat version
brain_age_df_combat_followup <-
  abcd_model_obj_combat_followup %>%
  predict(newdata = as.matrix(model2_analysis_followup %>% select(-c(src_subject_id, interview_age)))) 

brain_age_df_combat_followup <- as.data.frame(brain_age_df_combat_followup) %>%
  mutate(
    # provide the chronological age at time of scan
    truth = model2_analysis_followup$interview_age
  ) %>%
  # compute the brain age gap by subtracting chronological age from prediction
  mutate(gap = .pred - truth)

```



Bias Correction
```{r}
#run model on validation set
abcd_brain_age_correction_followup <-
  fit_workflow_combat_followup %>%
  predict(new_data = df_validation_followup) %>%
  mutate(
    # provide the chronological age at time of scan
    truth = df_validation_followup$interview_age
  ) %>%
  # compute the brain age gap by subtracting chronological age from prediction
  mutate(gap = .pred - truth)


#get MAE for hold-out 
abcd_brain_age_correction_followup %>%
  metrics(truth = truth, estimate = .pred)

abcd_bias_mod_followup <- lm(.pred ~ truth, data = abcd_brain_age_correction_followup)

# extract intercept and slope
#
abcd_bias_intercept_followup <- abcd_bias_mod_followup$coefficients[["(Intercept)"]]

abcd_bias_slope_followup <-  abcd_bias_mod_followup$coefficients[["truth"]]

  
# create bias correct data frame
#Baseline
brain_age_corrected_df_combat_followup <- brain_age_df_workflow_combat_followup %>%
  mutate(
    # corrected brain age prediction
    corrected_pred =  (.pred - abcd_bias_intercept_followup) / abcd_bias_slope_followup
  ) %>%
  # corrected corrected brain age gap
  mutate(corrected_gap = corrected_pred - truth)

```


Clean up & save
```{r}
# add IDs back
brain_age_corrected_df_combat_followup$src_subject_id <- model2_analysis_followup$src_subject_id

brain_age_corrected_df_combat_followup <- brain_age_corrected_df_combat_followup %>% 
  select(6, 1:5)

# save dataframe
save(brain_age_corrected_df_combat_followup, file = "brain_age_corrected_df_combat_followup.Rda")

```

